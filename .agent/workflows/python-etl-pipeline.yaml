name: Python ETL Pipeline Workflow
description: >
  Design and implement a Python-based ETL/ELT data pipeline that is
  environment-aware and independent of hard-coded paths.

triggers:
  - user_request: "build python etl"
  - user_request: "create data pipeline"
  - user_request: "convert scripts into a pipeline"

assumptions:
  - Data lives under project-relative directories or configurable locations.
  - The user is open to orchestrating the pipeline via a scheduler or
    orchestration tool. 

steps:
  - name: Identify data sources and sinks
    action: analyze_repository
    description: >
      Locate relevant code, configuration, and data directories, and ask the
      user to confirm sources (files, APIs, databases) and targets (warehouse,
      lake, analytics tables). 

  - name: Define path-agnostic configuration
    action: modify_files
    description: >
      Create or update configuration files (for example, config/pipeline.yaml)
      with relative data paths (for example, "data/raw", "data/processed") and
      connection settings keyed by environment (dev, staging, prod).

  - name: Modularize pipeline code
    action: refactor_code
    description: >
      Organize pipeline steps into functions/modules under src/, such as:
        - src/ingest.py
        - src/transform.py
        - src/load.py
      Ensure each step accepts configuration and paths as parameters rather than
      hard-coded constants. 

  - name: Implement orchestrated entrypoint
    action: modify_files
    description: >
      Add an entrypoint script (for example, src/pipeline.py) or simple
      orchestration definitions (for example, Dagster jobs, Prefect flows,
      Airflow DAGs) that run the ETL/ELT steps in order. 

  - name: Add tests and validation
    action: modify_files
    description: >
      Create tests (for example, tests/test_pipeline.py) and basic
      data-validation checks to ensure schema and data quality, using
      project-relative test data. 

  - name: Document pipeline usage
    action: summarize
    description: >
      Provide commands and examples for running the pipeline for different
      environments, configured via CLI flags or environment variables rather
      than absolute paths.
